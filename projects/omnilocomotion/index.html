<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> No More Blind Spots: Learning Vision-Based Omnidirectional Bipedal Locomotion for Challenging Terrain | Mohit Gadde </title> <meta name="author" content="Mohit Gadde"> <meta name="description" content="&lt;strong&gt;Mohitvishnu S. Gadde&lt;/strong&gt;, Pranay Dugar, Ashish Malik, Alan Fern &lt;em&gt;2025 IEEE Humanoids&lt;/em&gt;"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://mohittgadde.com/projects/omnilocomotion/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Mohit</span> Gadde </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">research <span class="sr-only">(current)</span> </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">No More Blind Spots: Learning Vision-Based Omnidirectional Bipedal Locomotion for Challenging Terrain</h1> <p class="post-description"><strong>Mohitvishnu S. Gadde</strong>, Pranay Dugar, Ashish Malik, Alan Fern <em>2025 IEEE Humanoids</em></p> </header> <article> <div style="width: 100%; display: flex; justify-content: center; font-size: 25px; margin-bottom: 1rem; flex-direction: row; flex-wrap: wrap;"> <a style="margin: 5px;" href="https://arxiv.org/abs/2508.11929" rel="external nofollow noopener" target="_blank">[ Paper ]</a> </div> <h2 id="abstract">Abstract</h2> <p>Effective bipedal locomotion in dynamic environments, such as cluttered indoor spaces or uneven terrain, requires agile and adaptive movement in all directions. This necessitates omnidirectional terrain sensing and a controller capable of processing such input. We present a learning framework for vision-based omnidirectional bipedal locomotion, enabling seamless movement using depth images. A key challenge is the high computational cost of rendering omnidirectional depth images in simulation, making traditional sim-to-real reinforcement learning (RL) impractical. Our method combines a robust blind controller with a teacher policy that supervises a vision-based student policy, trained on noise-augmented terrain data to avoid rendering costs during RL and ensure robustness. We also introduce a data augmentation technique for supervised student training, accelerating training by up to 10 times compared to conventional methods. Our framework is validated through simulation and real-world tests, demonstrating effective omnidirectional locomotion with minimal reliance on expensive rendering. This is, to the best of our knowledge, the first demonstration of vision-based omnidirectional bipedal locomotion, showcasing its adaptability to diverse terrains.</p> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/humanoids2025/intro_img-480.webp 480w,/assets/img/humanoids2025/intro_img-800.webp 800w,/assets/img/humanoids2025/intro_img-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/humanoids2025/intro_img.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Intro Image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Our fully learned controller integrates vision and locomotion for reactive and agile gaits over terrains. The proposed approach enables bipedal robot Cassie traversing over challenging terrains, including random high blocks, stairs, 0.5m step up (∼60% leg length), with speed up to 1m/s. </div> <h2 id="system_arch">System Architecture</h2> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/icra2024/system_arch-480.webp 480w,/assets/img/icra2024/system_arch-800.webp 800w,/assets/img/icra2024/system_arch-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/icra2024/system_arch.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Intro Image" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Overview of the locomotion policy with vision module. </div> <p>The above image illustrates the overall system, which has two main components: (1) a locomotion policy, which outputs PD setpoints for the robot actuators based on proprioception, a local terrain heightmap, and user commands, and (2) a heightmap predictor, which outputs a predicted heightmap based on proprioceptive information and images from a depth camera. These components are learned in simulation and then transferred to the real robot (Cassie).</p> <h2 id="policy">Terrain Aware Policy and Heightmap Predictor</h2> <div class="row justify-content-sm-center"> <div class="col-sm-6 mt-3 mt-md-5 text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/icra2024/policy_arch-480.webp 480w,/assets/img/icra2024/policy_arch-800.webp 800w,/assets/img/icra2024/policy_arch-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/icra2024/policy_arch.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Policy Architecture" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Policy Architecture</div> </div> <div class="col-sm-6 mt-3 mt-md-0 text-center"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/icra2024/hm_predictor-480.webp 480w,/assets/img/icra2024/hm_predictor-800.webp 800w,/assets/img/icra2024/hm_predictor-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/icra2024/hm_predictor.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="Heightmap Predictor" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <div class="caption">Heightmap Predictor</div> </div> </div> <p>The policy here is represented by a neural network that maps observation sequences to actions. It consists of two key components: a pretrained blind policy and a vision-based modulator. The blind policy provides a baseline locomotion control signal suitable for moderate terrains. For more complex terrain, the vision-based modulator refines the baseline control by incorporating local terrain details, enabling more adaptive and robust locomotion.</p> <p><strong>Heightmap Predictor</strong> is a neural network that estimates the terrain heightmap ahead of the robot using depth images and robot states. It consists of two stages: <strong>Stage 1</strong> uses an LSTM to reconstruct missing terrain details by leveraging temporal information, trained with mean-squared error loss. <strong>Stage 2</strong> refines the heightmap using a U-Net, enhancing edge sharpness and surface flatness with L1 loss, resulting in more accurate and stable predictions.</p> <h2 id="experiments">Experiments</h2> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/icra2024/terrain-480.webp 480w,/assets/img/icra2024/terrain-800.webp 800w,/assets/img/icra2024/terrain-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/icra2024/terrain.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="terrain" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> Various terrains used to train the terrain aware locmotion policy </div> <div class="row justify-content-sm-center mt-3"> <div class="col-sm-8"> <div class="video-container"> <iframe width="100%" height="400" src="https://www.youtube.com/embed/6kgB8PqvLYU" title="Experiments Video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""> </iframe> </div> </div> </div> <h2 id="results">Results</h2> <div class="row justify-content-sm-center"> <div class="col-12 mt-6 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/icra2024/results-480.webp 480w,/assets/img/icra2024/results-800.webp 800w,/assets/img/icra2024/results-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/icra2024/results.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="results" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <p><strong>[A]</strong> Ablation study on policy with simulation heightmap. <strong>[B]</strong> Ablation study on policy with different heightmap predictor architectures. Each ablation study uses data collected from a range of terrains defined in Table I. <strong>Success rate</strong> indicates the robot does not fall down for 10 seconds of rollouts. <strong>Episodes with foot collision</strong> indicates the number of episodes that have one or more foot collision events occurred during rollouts, and such random collision events are unfavorable towards hardware deployment. <strong>Termination due to foot collision</strong> shows the percentage of foot collision events that lead to failures. All plots are evaluated with a confidence interval of <strong>95%</strong>.</p> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2026 Mohit Gadde. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>